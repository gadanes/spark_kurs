{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f70bb7a-4f7c-4abc-8e81-7675f3445aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Localspark\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.jars.packages\",\n",
    "        \"com.microsoft.sqlserver:mssql-jdbc:12.6.1.jre11\") \\\n",
    "    .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b1281ac-5bae-4754-8a1f-86edf4815987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load variables from .env into os.environ\n",
    "load_dotenv(\"env\")\n",
    "server_name = os.environ.get(\"SERVERNAME\")\n",
    "database_name = os.environ.get(\"DATABASENAME\")\n",
    "username = os.environ.get(\"USERNAME\")\n",
    "password = os.environ.get(\"PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e863277-0255-49f3-bf94-537f0eb7679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard JDBC URL format for SQL Server\n",
    "jdbc_url = f\"jdbc:sqlserver://{server_name}:1433;databaseName={database_name}\"\n",
    "\n",
    "#table name to read\n",
    "table_name = \"BIB.Autor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64023a2a-b8aa-4b73-a27b-d06f3ca008ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID_Autor: integer (nullable = true)\n",
      " |-- Vorname_1: string (nullable = true)\n",
      " |-- Vorname_2: string (nullable = true)\n",
      " |-- Nachname: string (nullable = true)\n",
      "\n",
      "+--------+---------+---------+--------+\n",
      "|ID_Autor|Vorname_1|Vorname_2|Nachname|\n",
      "+--------+---------+---------+--------+\n",
      "|       1|      Abe|     NULL|    Kobo|\n",
      "|       2|   Chinua|     NULL|  Achebe|\n",
      "|       3|  Theodor|       W.|  Adorno|\n",
      "|       4|     NULL|     NULL|    Äsop|\n",
      "|       5|   Samuel|     NULL|   Agnon|\n",
      "+--------+---------+---------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    jdbcDF = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "        .option(\"url\", jdbc_url) \\\n",
    "        .option(\"dbtable\", table_name) \\\n",
    "        .option(\"user\", username) \\\n",
    "        .option(\"password\", password) \\\n",
    "        .load()\n",
    "\n",
    "    # Display schema and a few rows if successful\n",
    "    jdbcDF.printSchema()\n",
    "    jdbcDF.show(5)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"JDBC read failed!\")\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c67ae42-3864-4997-ba3c-9dc20f4688bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "autor_df = jdbcDF.select(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4aa28b13-0bbd-480b-ab70-41859716180b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+--------------+\n",
      "|ID_Autor|Vorname_1|Vorname_2|      Nachname|\n",
      "+--------+---------+---------+--------------+\n",
      "|       1|      Abe|     NULL|          Kobo|\n",
      "|       2|   Chinua|     NULL|        Achebe|\n",
      "|       3|  Theodor|       W.|        Adorno|\n",
      "|       4|     NULL|     NULL|          Äsop|\n",
      "|       5|   Samuel|     NULL|         Agnon|\n",
      "|       6|     Ilse|     NULL|     Aichinger|\n",
      "|       7|Tschingis|     NULL|      Aitmatow|\n",
      "|       8|     NULL|     NULL|Alain-Fournier|\n",
      "|       9|    Mateo|     NULL|        Alemán|\n",
      "|      10|   Nelson|     NULL|        Algren|\n",
      "|      11|   Isabel|     NULL|       Allende|\n",
      "|      12|    Jorge|     NULL|         Amado|\n",
      "|      13|   Ingvar|     NULL|    Ambjørnsen|\n",
      "|      14|     Eric|     NULL|        Ambler|\n",
      "|      15|     Jean|     NULL|         Améry|\n",
      "|      16|  Günther|     NULL|        Anders|\n",
      "|      17|   Alfred|     NULL|      Andersch|\n",
      "|      18|     Hans|Christian|      Andersen|\n",
      "|      19|   Martin| Andersen|          Nexø|\n",
      "|      20| Sherwood|     NULL|      Anderson|\n",
      "+--------+---------+---------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "autor_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed437911-5a02-4ca7-a01f-e5fe4d0cebf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
